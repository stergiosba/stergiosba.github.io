"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[503],{7180:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"Swarm_pub/icra","title":"Learning Adversarial Policies for Swarm Leader Identification Using a Probing Agent","description":"Venue: 2025 IEEE International Conference on Robotics and Automation (ICRA).","source":"@site/docs/Swarm_pub/icra.md","sourceDirName":"Swarm_pub","slug":"/Swarm_pub/icra","permalink":"/docs/Swarm_pub/icra","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Swarm_pub/icra.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Swarm Publications","permalink":"/docs/category/swarm-publications"},"next":{"title":"On Swarm Leader Identification using Probing Policies","permalink":"/docs/Swarm_pub/tase"}}');var a=i(4848),r=i(8453);const o={sidebar_position:5},s="Learning Adversarial Policies for Swarm Leader Identification Using a Probing Agent",c={},d=[{value:"Abstract:",id:"abstract",level:2}];function l(e){const t={h1:"h1",h2:"h2",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"learning-adversarial-policies-for-swarm-leader-identification-using-a-probing-agent",children:"Learning Adversarial Policies for Swarm Leader Identification Using a Probing Agent"})}),"\n",(0,a.jsx)(t.p,{children:"Venue: 2025 IEEE International Conference on Robotics and Automation (ICRA)."}),"\n",(0,a.jsx)(t.p,{children:"Date of Conference: 19-23 May 2025"}),"\n",(0,a.jsx)(t.h2,{id:"abstract",children:"Abstract:"}),"\n",(0,a.jsx)(t.p,{children:"This study introduces a novel approach to swarm leader identification (SLI) in multi-agent robot systems by employing a physical adversary interacting with the swarm in the same environment. We develop a new simulation environment to study the SLI problem and train an adversary, which we term the prober, to solve the SLI problem using forceful interactions with the swarm as its guiding information source. The prober's policy is modeled using the simplified structure state space sequence (S5) model and trained with the Proximal Policy Optimization (PPO) algorithm. The prober only has access to the information on the relative positions of the other agents. We evaluate our approach through extensive simulations using two performance metrics and validate the sim-to-real transfer through robot experiments. Results on evaluating the performance in 10,000 different testing scenarios demonstrate that our method finds the leader's identity in the vast majority (95.7%) of the cases, regardless of the initial leader selection during training. The proposed system represents the first instance of learning-based automatic identification of leader agents in a swarm. This capability is crucial for enabling efficient and robust human-swarm interaction, understanding artificial swarm behaviors, and analyzing latent behaviors in biological swarms in nature."})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>o,x:()=>s});var n=i(6540);const a={},r=n.createContext(a);function o(e){const t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);